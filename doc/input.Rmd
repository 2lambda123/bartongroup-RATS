---
title: 'RATs: Input and Settings'
author: "Kimon Froussios"
date: "04 FEB 2019"
output:
  html_document:
    theme: readable
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
vignette: >
  \usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{RATs 2: Input & Settings}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
library(rats)
```

***

# Input formats

## Data

RATs can work with several input types:

1. [Salmon](https://github.com/COMBINE-lab/salmon) and [Kallisto](http://pachterlab.github.io/kallisto/) quantifications.
2. Bootstrapped abundance estimates in lists of R `data.table`s.
3. Abundance estimates in R `data.table`s.

For option 1, the function `fish4rodents()` will load the data into tables suitable for option 2. Details in the respective 
section below. For options 2 and 3, the format of the tables is as in the example below. The first column contains the transcript identifiers.
Subsequent columns contain the abundances.

```{r, echo=FALSE}
# Show the first rows of the table corresponding to one sample, from emulated data.
head(sim_boot_data()[[2]][[1]])
```

* In the case of option 3, each column represents a sample. Each condition is represented by a single such table.
* In the case of option 2, each column represents a bootstrap iteration and each table represents a sample. Each 
condition is represented by a list of such tables.

### Read counts, TPMs, etc

RATs will happily crunch any type of numeric value, but the type of abundances you provide will have an impact on the DTU outcome. 
The statistical test employed (G test) is meant to work with counts, not arbitrarily scaled values like TPMs (transcripts per million reads) 
or other per-million-reads representations. On the other hand, raw read counts work well with RATs and achieve a good False Discovery Rate, 
but they are influenced by the length of the transcripts.

To get the best of both worlds, we recommend obtaining TPM abundances, so as to account for transcript lengths, 
and then scaling these values to your actual library sizes to regain count-like magnitudes. 
RATs provides parameters to scale the abundances per sample to meet this requirement.


## Annotation

Regardless of data format, RATs also needs an annotation `data.frame` or `data.table` that matches transcript identifiers to gene identifiers. 
By default the column labels are `target_id` for the transcript IDs and `parent_id` for the gene IDs. These label values can be overridden (see Additional Settings later in this vignette). The annotation table looks like this:

```{r, echo=FALSE}
# Show the first rows of the table corresponding to the annotation, from simulated data.
head(sim_count_data()[[1]])
```

Such a table can be compiled with a variety of methods and from a variety of resources. RATs provides functionality
to create this table from a GTF file or a `GRanges` object with GTF-style metadata columns. 
(**Note:** GFF3 is not supported for this)

```{r, eval=FALSE}
# Extract transcript ID to gene ID index from a GTF annotation.
myannot <- gtf2ids("my_annotation_file.gtf")
# !! gtf2ids() was previosuly called annot2ids(). The old name is still available but will eventally be discontinued.

# Extract transcript ID and gene ID from a GRanges object. It must have GTF-style metadata columns "gene_id" and "transcript_id".
myannot <- granges2ids(mygranges)
```

Extracting the ID pairs from a `TxDb` is simpler and does not require a dedicated helper function:

```{r eval=FALSE}
myannot <- select(mytxdb, keys(mytxdb), "TXNAME", "GENEID")
# Rename the columns to match what RATs expects, or remember to tell call_DTU() what the column names are.
names(myannot) <- c('gene_id', 'target_id')
```


***


# Calling DTU 


As input data, we will use the data emulators that RATs uses in its code tests. 
These "data" are extremely limited and completely fictional, but should suffice to demonstrate formats and syntax.

Progress messages, warnings and summury report can be supressed using the `verbose = FALSE` parameter. 
To prevent cluttering this tutorial with verbose output, we will use this option in our examples. 
If you choose to allow verbose output when trying out the examples below using the emulated data, you will get some **warnings**
about the number of bootstraps. The warning is triggered because the emulated dataset used in the examples immitates only the structure of 
real data, not the actual amount of it, and as such it contains unrealistically few bootstrap iterations. Simply ignore these warnings
for these examples.

First, we'll focus on the call syntax for the different input types, using default values for all the other parameters. 
Then we'll discuss separately the various parameters.


### DTU from abundance estimates, without bootstraps

This is the simplest usage case, and your likely input type if you use quantifications methods other than Kallisto and Salmon.

First, let's emulate some data to work with:

```{r}
# Simulate some data.
simdat <- sim_count_data(clean=TRUE)
# For convenience let's assign the contents of the list to separate variables
mycond_A <- simdat[[2]]       # Simulated abundances for one condition.
mycond_B <- simdat[[3]]       # Simulated abundances for other condition.
myannot <- simdat[[1]]        # Transcript and gene IDs for the above data.

# Each condition is a single data.table:
print( class(mycond_A) )
```

Now we can call DTU:

```{r}
# Find DTU between the simulated datasets.
mydtu <- call_DTU(annot= myannot, count_data_A= mycond_A, 
                  count_data_B= mycond_B, verbose= FALSE,
                  name_A= "healthy", name_B= "patients", 
                  varname= "My phenotype",
                  description="Comparison of two simulated counts datasets 
                  for the tutorial. Simulated using built-in functionality 
                  of RATs.")
```

#### Mandatory arguments:

1. `annot` - An annotation data frame, as described in the Input formats section.
2. `count_data_A` and `count_data_B` - Each is a `data.table` of transcript abundances as described in the Input formats section.

#### Optional arguments (will be recorded in the output object, but have no effect on the run):

* `name_A`, `name_B` - A name for each conditon. (Default `NA`)
* `varname` - The name of the variable/condition. (Default `NA`)
* `description` - Free-text description. (Default `NA`)



### DTU from bootstrapped abundance estimates

First, let's emulate some data, as we did before.

```{r}
# Simulate some data. (Notice it is a different function than before.)
simdat <- sim_boot_data(clean=TRUE)

# For convenience let's assign the contents of the list to separate variables
mycond_A <- simdat[[2]]   # Simulated bootstrapped data for one condition.
mycond_B <- simdat[[3]]   # Simulated bootstrapped data for other condition.
myannot <- simdat[[1]]    # Transcript and gene IDs for the above data.

# Each condition is a list of data.tables:
print( class(mycond_A) )
print( class(mycond_A[[1]]) )
```

Now we can call DTU:

```{r}
# Find DTU between conditions.
mydtu <- call_DTU(annot= myannot, boot_data_A= mycond_A, 
                  boot_data_B= mycond_B, verbose= FALSE, 
                  name_A= "wildtype", name_B= "some mutant", 
                  varname = "My phenotype", description="Comparison of 
                  two simulated datasets of bootstrapped counts for the 
                  tutorial. Simulated using built-in functionality 
                  of RATs.")
```

#### Mandatory arguments:

1. `annot` - An annotation data frame, as described in the *Input formats* section.
2. `boot_data_A` and `boot_data_B` - Each is a list of `data.table` objects, as described in the Input section.

#### Optional arguments (will be recorded in the output object, but have no effect on the run):

* `name_A`, `name_B` - A name for each conditon. (Default `NA`)
* `varname` - The name of the variable/condition. (Default `NA`)
* `description` - Free-text description. (Default `NA`)


### DTU with Salmon/Kallisto output

RATs offers a method to import bootstrapped abundances directly from [Salmon](https://combine-lab.github.io/salmon/) 
output (requires [wasabi](https://github.com/COMBINE-lab/wasabi)) or  [Kallisto](https://pachterlab.github.io/kallisto/) 
output. The raw abundances are normalised to TPM (default).

```{r, eval=FALSE}
# Mock-up code, does not run.

# 1. Collect your outputs into vectors. The end of each path should be a 
#    directory with a unique name/identifier for one sample.
samples_A <- c("your/path/SAMPLE1", "your/path/SAMPLE4","your/path/SAMPLE5")
samples_B <- c("your/path/SAMPLE2", "your/path/SAMPLE3","your/path/SAMPLE7", 
               "your/path/SAMPLE10")

# 2. Calculate length- & library-normalised abundances. 
#    Scale them to 1M reads for TPM values.
mydata <- fish4rodents(A_paths= samples_A, B_paths= samples_B, 
                       annot= myannot, scaleto=100000000)

# The output is two lists of data.tables:
print (class(mydata$boot_data_A))
print (class(mydata$boot_data_B))
print (class(mydata$boot_data_A[[1]]))
print (class(mydata$boot_data_A[[1]]))
```

This helper function works *only* with bootstrapped quantifications.
The abundaces are normalised for isoform length and library-size.

#### Mandatory arguments (`fish4rodents`):

1. `A_paths` and `B_paths` - Two vectors containing the paths to the quantification output directories, one vector for each condition. The
last segments of each path should be a directory with a unique identifying name for a single sample.
2. `annot` - An annotation data frame, as described in the *Input formats* section.

#### Optional arguments (`fish4rodents`):

* `scaleto` - allows you to control the normalisation factor. (Default 1000000 gives TPM values).
* `half_cooked` - indicates whether a kallisto-style abundance.h5 file already exists. (Default `FALSE`). `wasabi` automatically detects the presence of an abundance.h5 file, so this option is actually redundant.
* `beartext` - directs `fish4rodents()` to read bootstrap data from plain-text files in a `bootstraps` subdirectory in each sample, instead of parsing the abundance.h5 file of the sample. `kallisto` has the option to return plaintext results or to extract results from an existing abundance.h5 file to plaintext, using its `h5dump` subcommand. (Default FALSE)

And finally run DTU in the way already shown:

```{r, echo=FALSE}
# Since the fish4rodents code is a mock-up, create the input using something that does run:
simdat <- sim_boot_data(clean=TRUE)
mydata=list(boot_data_A=c(simdat[[2]], simdat[[3]][1]),
            boot_data_B=c(simdat[[3]], simdat[[2]]))
myannot <- simdat[[1]]
```

```{r}
# 3. Run RATs with the bootstrapped data format. 
#    Scale the TPM abundances to the respective library sizes.
#    For the example, assume library sizes of 25M, 26M, 23M, 50M, 45M, 
#    48M and 52M for the 7 samples, in the same order.
mydtu <- call_DTU(annot= myannot, boot_data_A= mydata$boot_data_A, 
                  boot_data_B= mydata$boot_data_B, verbose= FALSE, 
                  scaling=c(25, 26, 23, 50, 45, 48, 52))

# Remember that TPMs are already scaled to 1M, so scaling to the
# library size of 50M only requires a factor of 50, not 50000000!
```

#### Mandatory arguments:

* `scaling` - A vector of scaling factors, one per sample, that ensures that the abundances are scaled to the library size instead of 1M.


***


# Advanced Parameters and Settings

```{r, echo=FALSE}
simdat <- sim_boot_data(clean=TRUE)
mycond_A <- simdat[[2]]   # Simulated bootstrapped data for one condition.
mycond_B <- simdat[[3]]   # Simulated bootstrapped data for other condition.
myannot <- simdat[[1]]    # Transcript and gene IDs for the above data.
```

## Main Thresholds

The following three main thresholds are used in RATs:

```{r}
# Calling DTU with custom thresholds.
mydtu <- call_DTU(annot= myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  p_thresh= 0.01, dprop_thres = 0.15, abund_thresh= 10,
                  verbose= FALSE)
```

1. `p_thresh` - Statistical significance level. (Default 0.05, very permissive)
2. `dprop_thresh` - Effect size threshold: The minimum difference in the isoform's proportion between the two conditions. (Default 0.20, quite strict)
3. `abund_thresh` - Noise threshold: (i) The minimum mean (across replicates) abundance (in at least one condition) for a transcript to be considered expressed. (ii) Also the minimum cumulative abundance of all isoforms of a gene in each of the two conditions. (Default 5, very permissive)

Depending on the settings, *additional thresholds* are available and will be discussed in their respective sections below.
 

## Bootstrapping 

RATs offers two types of bootstrapping:

1. Bootstrapping of significance and effect size against the variability in the quantifications. 
This requires bootstrapped quantifications as input.
2. Bootstrapping of significance and effect size against the variability among samples.

Enabling these two procedures assesses the robustness of the DTU calls. In both cases, what is measured 
is the fraction of iterations in which the significance and effect size meet their respective thresholds.
**Note** If bootstrapping is switched off, the respective fields will not be included in the output.


### Quantification bootstraping

In this process, one quantification iteration will be randomly selected from each sample and DTU will be called on it. 
This will be repeated `qbootnum` times.

Three parameters control bootstrapping of DTU calls against the fluctuations in the quantification:

```{r}
# Bootstrap (default). Do 100 iterations.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  qboot = TRUE, qbootnum = 100, qrep_thresh= 0.95,
                  verbose= FALSE)

# Skip bootstraps.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  qboot = FALSE, verbose= FALSE)
```

1. `qboot` - Whether to bootstrap against the quantifications. (Default TRUE)
2. `qbootnum` - Number of bootstrap iterations. 0 is a special value prompting RATs to infer a value from the data (currently equal to the number of bootstraps in the data). (Default 0)
3. `qrep_thresh` - Reproducibility threshold: The minimum fraction of the iterations that have to agree on a result to consider it confident. (Default 0.95) To calculate the reproducibility without factoring it in the DTU classification, set the threshold to 0.


### Replicate bootstraping

In this process, all the 1 vs. 1 combinations of samples, one from each condition, are used to bootstrap the variation across replicates.

Two parameters control bootstrapping of DTU calls agaisnt the samples:

```{r}
# Bootstrap (default).
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  rboot = TRUE, qrep_thresh= 0.85, verbose= FALSE)

# Skip bootstraps.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  rboot = FALSE, verbose= FALSE)
```

1. `rboot` - Whether to bootstrap the replicates or not. (Default TRUE)
2. `rrep_thresh` - Reproducibility threshold: The minimum fraction of the iterations that have to agree on a result to consider it confident. (Default 0.85) To calculate the reproducibility without factoring it in the DTU classification, set the threshold to 0.

**Note** that for few replicates per condition, the reproducibility values are highly discrete, which affects what threshold
values are meaningful. For example, the number of iterations for 3 samples per condition is `3 * 3 = 9`. 
So the minimum disagreement rate is `1 / 9 = 0.111...`, or conversely a reproducibility of `8 / 9 = 0.888...`, 
hence the default threshold value of 0.85.

### Extra bootstrapping info

Additional information on the range, variance and centre of the effect size and p-value across bootstrap iterations can be calculated on demand. This requires keeping the full raw results for every iteration in memory and can have a considerable footprint that scales with the number of transcripts and iterations. This is controlled by the `lean` parameter.

```{r}
# Lean run (default).
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  lean =TRUE, verbose= FALSE)

# Extra info on variance across iterations.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  lean = FALSE, verbose= FALSE)
```

1. `lean` - Keep it light, report only the reproducibility rate. (Default TRUE)


## Abundance scaling

As mentioned previously, various commonly-used units of normalised abundance, such as TPM, are scaled to an arbitrary and usually 
smaller-than-actual sample size (often 1 million reads or fragments). This artificially reduces the statistical power from the
count-based tests employed by RATs. 

To counter this, RATs provides the option to scale abundaces either uniformly by a single factor (such as average library size 
among samples) or by a vector of factors (one factor per sample). Unlike differential transcript expression where libraries must
be normalised for size so that transcript abundances are comparable, abundances for differential transcript usage are normalised
for the expression of the respective individual gene. Therefore, RATs does not require the libraries to have the same size. However, 
larger libraries will receive more weight. This is probably a good thing, but it is your call to make.

For flexibility with different types of input, scaling can be applied in either/both of two stages: The data import step by 
`fish4rodents()`, or/and the actual testing step by `call_DTU()`. In an example examined previously, `fish4rodents()` was 
instructed to create TPM abundances, by normalising to `1000000` reads. Such values are useful with other tools that 
a user may also intend to use. Subsequently, these TPMs were re-scaled to reflect the library size of each sample, thus providing 
RATs with count-like abundance values that retain the normalisation by isoform length.

Both `fish4rodents()` and `call_DTU()` support scaling by a single value or a vector of values. If you don't need the TPMs, you can scale 
directly to the desired library size(s).

```{r, eval=FALSE}
# The following code cis for demonstration only and won't run
# without valid paths supplied to fish4rodents().

# The following are equivalent.

# 1:
# Scale to individual library sizes directly at the import step.
mydata <- fish4rodents(A_paths= samples_A, B_paths= samples_B, 
                       annot= myannot, 
                       scaleto=c(25123456, 2665431, 23131313, 
                                 5000000, 45123132, 48456654, 52363636),
                       verbose= FALSE)
# No additional scaling needed.
mydtu <- call_DTU(annot= myannot, boot_data_A= mydata$boot_data_A, 
                  boot_data_B= mydata$boot_data_B, 
                  scaling=1,  # default
                  verbose= FALSE)  

# 2:
# Normalise quantifications but do not scale them.
mydata <- fish4rodents(A_paths= samples_A, B_paths= samples_B, 
                       annot= myannot, 
                       scaleto=1)
# Scale uniformly to the smallest library size directly at the run step.
libsiz <- min(25123456, 2665431, 23131313, 5000000, 45123132, 48456654, 52363636)
mydtu <- call_DTU(annot= myannot, boot_data_A= mydata$boot_data_A, 
                  boot_data_B= mydata$boot_data_B,  
                  scaling=libsiz, verbose= FALSE)

# 3:
# Scale Kallisto/Salmon quantifications to TPMs.
mydata <- fish4rodents(A_paths= samples_A, B_paths= samples_B, 
                       annot= myannot, 
                       scaleto=10000000)  # default
# Scale TPMs to individual library sizes.
mydtu <- call_DTU(annot= myannot, boot_data_A= mydata$boot_data_A, 
                  boot_data_B= mydata$boot_data_B,
                  scaling=c(25.123456, 26.65431, 23.131313, 50.0, 45.123132, 48.456654, 52.363636), 
                  verbose= FALSE)
```

Take care to ensure that the scaling you apply is appropriate.
**It is important to note**, that if you simply run both methods with their respective defaults, you'll effectively run RATs 
on TPM values, which is extremely underpowered and not recommended. Please, provide appropriate scaling factors for your data.


## Multi-threading

RATs completion time depends on the number of annotated and expressed transcripts. Single-threaded, RATs can take up to 
a few minutes per iteration, for large annotations. Fortunately, the task is highly parallelisable:

```{r}
# Using 4 threads for parallel computing.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  threads = 4, verbose= FALSE)
```

1. `threads` - The number of threads to use. (Default 1)

There are some limitations imposed by R. Refer to the `parallel` package for details (RATs uses the `mclapply` family of
parallel functions).

## Correction for multiple testing

There are as many null hypotheses tested as there are genes (for the gene-level results) or transcripts (for the transcript-level results). 
The default correction method is `BH` (Benjamini-Hochberg). A full list of options is listed in R's `p.adjust.methods`.

```{r}
# Bonferroni correction.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  correction = "bonferroni", verbose= FALSE)
```

1. `correction` - Type of multiple testing correction. (Default "BH")

## Test selection

RATs runs both gene-level DTU calls and transcript-level DTU calls. They are independent from one another and we consider 
them complementary and recommend using them together, but the option to skip either is provided, for special use cases. 
The output fields of the skipped test will be filled with `NA`.

```{r}
# Transcripts only.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  testmode="transc", verbose= FALSE)
# Genes only.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  testmode="genes", verbose= FALSE)
```

1. `testmode` - Which test(s) to run {"transc", "genes", "both"}. (Default "both")

## Input field names

### Annotation field names

Although it is easy to rename the columns of a table to comply with the expected names, this may sometimes be undesireable, so RATs
allows you to change the expected names instead.

```{r, echo=FALSE}
simdat <- sim_boot_data(clean=TRUE, PARENT_COL='gene', TARGET_COL='transcript')
mycond_A <- simdat[[2]]   # Simulated bootstrapped data for one condition.
mycond_B <- simdat[[3]]   # Simulated bootstrapped data for other condition.
myannot <- simdat[[1]]    # Transcript and gene IDs for the above data.
```


```{r}
# Call DTU using annotation with custom field names.
mydtu <- call_DTU(annot = myannot, 
                  boot_data_A= mycond_A, boot_data_B= mycond_B,
                  TARGET_COL="transcript", PARENT_COL="gene",
                  verbose= FALSE)
```

1. `TARGET_COL` - The name of the field holding the transcript identifiers in the annotation data frame. (Default "target_id")
2. `PARENT_COL` - The name of the field holding the respective gene identifiers in the annotation data frame. (Default "parent_id")

The `TARGET_COL` and `PARENT_COL` parameters are also available for `fish4rodents()`.


## Annotation discrepancies

RATs will abort the run if the set of feature IDs in the provided annotation does not match fully the set of IDs in the quantifications.
If this happens, ensure you are using the exact same annotation throughout your workflow.

For special use cases, RATs provides the option to ignore the discrepancy and pretend everything is OK. Do this at your own risk.

```{r, eval=FALSE}
mydtu <- call_DTU(annot= myannot, boot_data_A= mydata$boot_data_A, 
                  boot_data_B= mydata$boot_data_B,
                  reckless=TRUE, verbose=TRUE)
```

1. `reckless` - Ignore inconsistent set of IDs between annotation and quantifications. (Default FALSE)

In reckless mode, all internal operations and the output of RATs are based on the annotation provided:

* Any transcript IDs present in the data but missing from the annotation will be ignored and will not show up in the output at all, as they cannot be matched to the gene IDs.
* Any transcript ID present in the annotation but missing from the data will be included in the output as zero expression. They can be identified later as `NA` values in `$Transcripts[, .(stdevA, stdevB)]` as these fields are not used downstream by RATs. `NA` values in other numeric fields are explicitly overwritten with `0` to allow downstream interoperability.

***


# Contact information

The `rats` R package was developed within [The Barton Group](http://www.compbio.dundee.ac.uk) at [The University of Dundee](http://www.dundee.ac.uk)
by Dr. Kimon Froussios, Dr. Kira Mourão and Dr. Nick Schurch.

To **report problems** or **ask for assistance**, please raise a new issue [on the project's support forum](https://github.com/bartongroup/Rats/issues).
Providing a *reproducible working example* that demonstrates your issue is strongly encouraged to help us understand the problem. Also, be sure 
to **read the vignette(s)**, and browse/search the support forum before posting a new issue, in case your question is already answered there.

Enjoy!

![](./figs/rats_logo.png)
